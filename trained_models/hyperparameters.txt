batch_size = 16          # how many independent sequences (blocks) we process in parallel
block_size = 128          # how large each block is
max_iters = 12000
eval_interval = 500
learning_rate = 3e-4
device = "cuda" if torch.cuda.is_available() else "cpu"
eval_iters = 200
n_embd = 384              # number of embedding dimensions
n_head = 6
n_layer = 6
dropout = 0.2
